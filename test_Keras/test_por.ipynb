{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xwu/stk/test_Keras/test_por.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# fit the keras model on the dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, HL, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m36\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# evaluate the keras model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X, HL, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# load the dataset\n",
    "dataset = loadtxt('total_data_free_edit.txt', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:31]\n",
    "HL = dataset[:,31]\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(31,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, HL, epochs=500, batch_size=36, verbose=0)\n",
    "# evaluate the keras model\n",
    "scores = model.evaluate(X, HL, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# save model and architecture to single file\n",
    "model.save(\"model_free.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "# load the dataset\n",
    "dataset = loadtxt('total_data_metal_V2.txt', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:31]\n",
    "HL = dataset[:,31]\n",
    "n = list(range(len(HL)))\n",
    "i = range(10)\n",
    "plt.subplot(222)\n",
    "plt.plot(i, HL[:10], color='blue', marker='o', label='raw data')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4456.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def trunc(values, decs=0):\n",
    "    return np.trunc(values*10**decs)/(10**decs)\n",
    "\n",
    "from numpy import loadtxt\n",
    "# load the dataset\n",
    "dataset = loadtxt('total_data_free_edit.txt', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:31]\n",
    "HL = trunc(dataset[:,31], decs=2) \n",
    "\n",
    "arr_x = []\n",
    "for e in X:\n",
    "    for i in e:\n",
    "        arr_x.append(round(i,2))\n",
    "arr_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (324, 28)\n",
      "Training Labels Shape: (324,)\n",
      "Testing Features Shape: (108, 28)\n",
      "Testing Labels Shape: (108,)\n",
      "Mean Absolute Error: 0.04 eV.\n",
      "Accuracy: 94.61 %.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# load the dataset\n",
    "dataset = loadtxt('Ni_Zn_V4.txt', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "features = dataset[:,0:28]\n",
    "# Labels are the values we want to predict\n",
    "labels = dataset[:,30]\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "#print(predictions,test_labels)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "#print(errors)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'eV.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpcmlgjoks as temporary training directory\n",
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f18254a8c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f18254a8c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.259766. Found 486 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.049310\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpcmlgjoks/model/ with prefix 164648aa2916422f\n",
      "[INFO abstract_model.cc:1248] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f18105a13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f18105a13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7f18105a1d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7f18105a1d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the model.\n",
    "model_1 = tfdf.keras.RandomForestModel()\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(train_features, train_labels)\n",
    "\n",
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_features, test_labels, return_dict=True)\n",
    "print()\n",
    "\n",
    "# make class predictions with the model\n",
    "#predictions = (model_1.predict(labels))\n",
    "# summarize the first 5 cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 40)                1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31)                1271      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 31)                992       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 31)                992       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15)                480       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,031\n",
      "Trainable params: 5,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 0.15%\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model('model_free.h5')\n",
    "# summarize model.\n",
    "model.summary()\n",
    "# load dataset\n",
    "dataset = loadtxt(\"total_data_free_V2.txt\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "x = dataset[:,0:31]\n",
    "HL = dataset[:,31]\n",
    "# evaluate the model\n",
    "score = model.evaluate(x, HL, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linker 2-4 [24.  8.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  2.  0.]\n",
      "linker 4-6 [24.  8.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  2.  0.]\n",
      "unit 2-3 [332.1 120.   26.    2.    4.    4.    2.    4.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.    2.    0.    4.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1. ]\n",
      "unit 2-4 [664.21 240.    52.     4.     8.     8.     4.     8.     0.     0.\n",
      "   0.     0.     0.     0.     0.     4.     4.     0.     8.     0.\n",
      "   0.     0.     0.     0.     0.     0.     2.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('linker 2-4', np.array([666.23, 242, 52, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 4, 2])- np.array([642.23, 234, 50, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 2, 2]))\n",
    "print('linker 4-6', np.array([690.23, 250, 54, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 6, 2])-np.array([666.23, 242, 52, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 4, 2]))\n",
    "\n",
    "print('unit 2-3', np.array([974.33, 354, 76, 6, 12, 12, 6, 12, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 12, 0, 0, 0, 0, 0, 0, 2, 3])-np.array([642.23, 234, 50, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 2, 2]))\n",
    "print('unit 2-4', np.array([1306.44, 474, 102, 8, 16, 16, 8, 16, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 16, 0, 0, 0, 0, 0, 0, 2, 4])-np.array([642.23, 234, 50, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13910.08,  5010.  ,  1092.  ,    80.  ,   160.  ,   160.  ,\n",
       "          80.  ,   160.  ,     0.  ,     0.  ,     0.  ,     0.  ,\n",
       "           0.  ,     0.  ,     0.  ,    80.  ,    80.  ,     0.  ,\n",
       "         160.  ,     0.  ,     0.  ,     0.  ,     0.  ,     0.  ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*30\n",
    "np.around([1.391008e+04, 5.010000e+03, 1.092000e+03, 8.000000e+01,\n",
    "        1.600000e+02, 1.600000e+02, 8.000000e+01, 1.600000e+02,\n",
    "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
    "        0.000000e+00, 0.000000e+00, 0.000000e+00, 8.000000e+01,\n",
    "        8.000000e+01, 0.000000e+00, 1.600000e+02, 0.000000e+00,\n",
    "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[738.23 266.    58.     4.     8.     8.     4.     8.     0.     0.\n",
      "   0.     0.     0.     0.     0.     4.     4.     0.     8.     0.\n",
      "   0.     0.     0.     0.     0.    10.     2.  ]\n",
      "[4611.28 1650.    364.     24.     48.     48.     24.     48.      0.\n",
      "    0.      0.      0.      0.      0.      0.     24.     24.      0.\n",
      "   48.      0.      0.      0.      0.      0.      0.      8.     12.  ]\n",
      "[7268.08 2610.    572.     40.     80.     80.     40.     80.      0.\n",
      "    0.      0.      0.      0.      0.      0.     40.     40.      0.\n",
      "   80.      0.      0.      0.      0.      0.      0.      8.     20.  ]\n",
      "[1.058908e+04 3.810000e+03 8.320000e+02 6.000000e+01 1.200000e+02\n",
      " 1.200000e+02 6.000000e+01 1.200000e+02 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 6.000000e+01 6.000000e+01 0.000000e+00 1.200000e+02 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 8.000000e+00 3.000000e+01]\n",
      "[1.391008e+04 5.010000e+03 1.092000e+03 8.000000e+01 1.600000e+02\n",
      " 1.600000e+02 8.000000e+01 1.600000e+02 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 8.000000e+01 8.000000e+01 0.000000e+00 1.600000e+02 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 8.000000e+00 4.000000e+01]\n",
      "[1.723108e+04 6.210000e+03 1.352000e+03 1.000000e+02 2.000000e+02\n",
      " 2.000000e+02 1.000000e+02 2.000000e+02 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 1.000000e+02 1.000000e+02 0.000000e+00 2.000000e+02 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 8.000000e+00 5.000000e+01]\n"
     ]
    }
   ],
   "source": [
    "# H_C10_2\n",
    "print(np.array([714.23, 258, 56, 4, 8, 8, 4, 8, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 8, 0, 0, 0, 0, 0, 0, 8, 2]) + np.array([24, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]))\n",
    "# H_C8_12\n",
    "print(np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*2)\n",
    "# H_C8_20\n",
    "print(np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*10)\n",
    "# H_C8_30\n",
    "print(np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*20)\n",
    "# H_C8_40\n",
    "print(np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*30)\n",
    "# H_C8_50\n",
    "print(np.array([3947.08, 1410, 312, 20, 40, 40, 20, 40, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 40, 0, 0, 0, 0, 0, 0, 8, 10]) + np.array([332.1, 120, 26, 2, 4, 4, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1])*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linker 2-4 [24.  8.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  2.  0.]\n",
      "linker 4-6 [24.  8.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  2.  0.]\n",
      "Fe unit 2-3 [386.025 126.     27.      0.      4.      4.      0.      5.      0.\n",
      "   0.      0.      0.      0.      0.      0.      4.      0.      0.\n",
      "   4.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.   ]\n",
      "Fe unit 2-4 [772.051 252.     54.      0.      8.      8.      0.     10.      0.\n",
      "   0.      0.      0.      0.      0.      0.      8.      0.      0.\n",
      "   4.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   2.   ]\n",
      "Ni unit 2-3 [388.026 128.     27.      0.      4.      4.      0.      5.      0.\n",
      "   0.      0.      0.      0.      0.      0.      4.      0.      0.\n",
      "   4.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.   ]\n",
      "Ni unit 3-4 [388.026 128.     27.      0.      4.      4.      0.      5.      0.\n",
      "   0.      0.      0.      0.      0.      0.      4.      0.      0.\n",
      "   4.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.   ]\n"
     ]
    }
   ],
   "source": [
    "# metal\n",
    "import numpy as np\n",
    "print('linker 2-4', np.array([774.067, 254, 54, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 2, 0, 0, 0, 0, 0, 0, 26, 4, 2])- np.array([750.067, 246, 52, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 2, 2]))\n",
    "print('linker 4-6', np.array([798.067, 262, 56, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 4, 0, 0, 0, 0, 0, 0, 26, 6, 2])-np.array([774.067, 254, 54, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 2, 0, 0, 0, 0, 0, 0, 26, 4, 2]))\n",
    "\n",
    "print('Fe unit 2-3', np.array([1136.092, 372, 79, 0, 12, 12, 0, 15, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 4, 0, 0, 0, 0, 0, 0, 26, 2, 3])-np.array([750.067, 246, 52, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 2, 2]))\n",
    "print('Fe unit 2-4', np.array([1522.118, 498, 106, 0, 16, 16, 0, 20, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 4, 0, 0, 0, 0, 0, 0, 26, 2, 4])-np.array([750.067, 246, 52, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 2, 2]))\n",
    "\n",
    "print('Ni unit 2-3', np.array([1142.093, 378, 79, 0, 12, 12, 0, 15, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 4, 0, 0, 0, 0, 0, 0, 28, 2, 3])-np.array([754.067, 250, 52, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 2, 2]))\n",
    "print('Ni unit 3-4', np.array([1530.119, 506, 106, 0, 16, 16, 0, 20, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 8, 0, 0, 0, 0, 0, 0, 28, 2, 4]) - np.array([1142.093, 378, 79, 0, 12, 12, 0, 15, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 4, 0, 0, 0, 0, 0, 0, 28, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850.067 282.     60.      0.      8.      8.      0.     10.      0.\n",
      "   0.      0.      0.      0.      0.      0.      8.      0.      0.\n",
      "   6.      0.      0.      0.      0.      0.      0.     28.     10.\n",
      "   2.   ]\n",
      "[2522.171  834.     178.       0.      24.      24.       0.      30.\n",
      "    0.       0.       0.       0.       0.       0.       0.      24.\n",
      "    0.       0.      16.       0.       0.       0.       0.       0.\n",
      "    0.      28.       8.       6.   ]\n",
      "[3298.223 1090.     232.       0.      32.      32.       0.      40.\n",
      "    0.       0.       0.       0.       0.       0.       0.      32.\n",
      "    0.       0.      24.       0.       0.       0.       0.       0.\n",
      "    0.      28.       8.       8.   ]\n"
     ]
    }
   ],
   "source": [
    "# Ni_H_C10_2\n",
    "print(np.array([826.067, 274, 58, 0, 8, 8, 0, 10, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 4, 0, 0, 0, 0, 0, 0, 28, 8, 2]) + np.array([24, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0]))\n",
    "# Ni_H_C8_6\n",
    "print(np.array([1746.119, 578, 124, 0, 16, 16, 0, 20, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 8, 0, 0, 0, 0, 0, 0, 28, 8, 4]) + np.array([388.026, 128, 27, 0, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1])*2)\n",
    "# Ni_H_C8_10\n",
    "print(np.array([1746.119, 578, 124, 0, 16, 16, 0, 20, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 8, 0, 0, 0, 0, 0, 0, 28, 8, 4]) + np.array([388.026, 128, 27, 0, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1])*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "X=[[738.23, 266.0, 58.0, 4.0, 8.0, 8.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0], [4279.18, 1530.0, 338.0, 22.0, 44.0, 44.0, 22.0, 44.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0]], Predicted=[[1.1215177]\n",
      " [0.6457527]]\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "import tensorflow as tf\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model('model_free_2.h5')\n",
    "\n",
    "#dataset2 = loadtxt('total_data_TPP.txt', delimiter=',')\n",
    "# new instance where we do not know the answer\n",
    "Xnew = np.array([[738.23,266,58,4,8,8,4,8,0,0,0,0,0,0,0,4,4,0,8,0,0,0,0,0,0,10,2],[4279.18,1530,338,22,44,44,22,44,0,0,0,0,0,0,0,22,22,0,44,0,0,0,0,0,0,8,11]])\n",
    "# make a prediction\n",
    "# make a prediction\n",
    "ynew = model.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew.tolist(), ynew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "X=[[850.067, 282.0, 60.0, 0.0, 8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 2.0], [2522.171, 834.0, 178.0, 0.0, 24.0, 24.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 8.0, 6.0], [3298.223, 1090.0, 232.0, 0.0, 32.0, 32.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 8.0, 8.0]], Predicted=[[1.2083652 ]\n",
      " [0.9056128 ]\n",
      " [0.81442356]]\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "import tensorflow as tf\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model('model_metal.h5')\n",
    "\n",
    "#dataset2 = loadtxt('total_data_TPP.txt', delimiter=',')\n",
    "# new instance where we do not know the answer\n",
    "Xnew = np.array([[850.067,282,60,0,8,8,0,10,0,0,0,0,0,0,0,8,0,0,6,0,0,0,0,0,0,28,10,2],[2522.171,834,178,0,24,24,0,30,0,0,0,0,0,0,0,24,0,0,16,0,0,0,0,0,0,28,8,6],[3298.223,1090,232,0,32,32,0,40,0,0,0,0,0,0,0,32,0,0,24,0,0,0,0,0,0,28,8,8]])\n",
    "# make a prediction\n",
    "# make a prediction\n",
    "ynew = model.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew.tolist(), ynew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'range' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xwu/stk/test_Keras/test_por.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m19\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.31.155.198/home/xwu/stk/test_Keras/test_por.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'range' and 'int'"
     ]
    }
   ],
   "source": [
    "i = range(19)\n",
    "i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397d3ee8216f1087e9ec1dfaa50a720e5fbbe591aec17f11bad4304fc35992d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
